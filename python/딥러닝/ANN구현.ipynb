{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST (손글씨)\n",
    "data = datasets.mnist\n",
    "(train_x, train_y), (test_x, test_y) = data.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (60000,), (10000, 28, 28), (10000,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape, train_y.shape, test_x.shape, test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(train_x[2], 'gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검증데이터 분리\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_x, valid_x, train_y, valid_y = train_test_split(train_x, train_y, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((45000, 28, 28), (15000, 28, 28), (45000,), (15000,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape, valid_x.shape, train_y.shape, valid_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8, 7, 9, 8, 0, 5, 8, 6, 2, 1], dtype=uint8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "28*28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델에 입력하기 위해 차원 변경\n",
    "# 스케일 조정(MinMax) 색상범위값 255로 나눔\n",
    "train_x = train_x.reshape(train_x.shape[0],28*28)/255\n",
    "valid_x = valid_x.reshape(valid_x.shape[0],28*28)/255\n",
    "test_x = test_x.reshape(test_x.shape[0],28*28)/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-c1626dec7d37>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_x\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_x\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_x\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'train_x' is not defined"
     ]
    }
   ],
   "source": [
    "train_x.shape, valid_x.shape, test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8, 7, 9, 8, 0, 5, 8, 6, 2, 1], dtype=uint8)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label(정답)의 categorical값 -> 원핫인코딩\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "train_y = to_categorical(train_y)\n",
    "valid_y = to_categorical(valid_y)\n",
    "test_y = to_categorical(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 1., 0.], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 신경망(ANN) 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "from tensorflow.keras.models import Sequential # 모델객체생성을 위한 클래스\n",
    "from tensorflow.keras.layers import Dense # 레이어추가를 위한 클래스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.7399 - accuracy: 0.7675 - val_loss: 0.2300 - val_accuracy: 0.9318\n",
      "Epoch 2/10\n",
      "900/900 [==============================] - 1s 960us/step - loss: 0.1811 - accuracy: 0.9469 - val_loss: 0.1577 - val_accuracy: 0.9534\n",
      "Epoch 3/10\n",
      "900/900 [==============================] - 1s 956us/step - loss: 0.1202 - accuracy: 0.9624 - val_loss: 0.1389 - val_accuracy: 0.9583\n",
      "Epoch 4/10\n",
      "900/900 [==============================] - 1s 995us/step - loss: 0.0991 - accuracy: 0.9705 - val_loss: 0.1259 - val_accuracy: 0.9629\n",
      "Epoch 5/10\n",
      "900/900 [==============================] - 1s 976us/step - loss: 0.0816 - accuracy: 0.9742 - val_loss: 0.1298 - val_accuracy: 0.9627\n",
      "Epoch 6/10\n",
      "900/900 [==============================] - 1s 945us/step - loss: 0.0677 - accuracy: 0.9789 - val_loss: 0.1266 - val_accuracy: 0.9650\n",
      "Epoch 7/10\n",
      "900/900 [==============================] - 1s 998us/step - loss: 0.0567 - accuracy: 0.9828 - val_loss: 0.1200 - val_accuracy: 0.9653\n",
      "Epoch 8/10\n",
      "900/900 [==============================] - 1s 971us/step - loss: 0.0490 - accuracy: 0.9850 - val_loss: 0.1253 - val_accuracy: 0.9642\n",
      "Epoch 9/10\n",
      "900/900 [==============================] - 1s 956us/step - loss: 0.0442 - accuracy: 0.9865 - val_loss: 0.1199 - val_accuracy: 0.9692\n",
      "Epoch 10/10\n",
      "900/900 [==============================] - 1s 947us/step - loss: 0.0341 - accuracy: 0.9892 - val_loss: 0.1365 - val_accuracy: 0.9646\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1bbbceba400>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 랜덤시드값\n",
    "tf.random.set_seed(14)\n",
    "\n",
    "# 모델 구현\n",
    "model = Sequential() # 객체 생성\n",
    "\n",
    "# 데이터 입력받는 레이어\n",
    "# Dense(출력데이터차원, 활성화함수, 입력데이터차원)\n",
    "model.add(Dense(64, activation='relu', input_shape=(28*28,)))\n",
    "\n",
    "# 레이어 추가\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "\n",
    "# 출력레이어\n",
    "# label 값의 종류만큼 차원 지정\n",
    "# 활성화함수 -> softmax\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# 모델 설정\n",
    "# compile()\n",
    "# 최적화기법 : adam(learning_rate=0.001)\n",
    "# 손실함수 : categorical_crossentropy\n",
    "# 평가지표 : accuracy\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 학습\n",
    "# epochs : 학습횟수\n",
    "# validation_data : 검증데이터\n",
    "model.fit(train_x, train_y, epochs=10, batch_size=50, validation_data=(valid_x, valid_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 790us/step - loss: 0.1326 - accuracy: 0.9660\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.1325613260269165, 0.9660000205039978]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 테스트데이터 평가\n",
    "# 손실값, 정확도\n",
    "model.evaluate(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 1.8944 - accuracy: 0.3853 - val_loss: 0.6804 - val_accuracy: 0.8628\n",
      "Epoch 2/10\n",
      "900/900 [==============================] - 1s 943us/step - loss: 0.5534 - accuracy: 0.8858 - val_loss: 0.3447 - val_accuracy: 0.9198\n",
      "Epoch 3/10\n",
      "900/900 [==============================] - 1s 960us/step - loss: 0.3095 - accuracy: 0.9282 - val_loss: 0.2683 - val_accuracy: 0.9327\n",
      "Epoch 4/10\n",
      "900/900 [==============================] - 1s 957us/step - loss: 0.2349 - accuracy: 0.9449 - val_loss: 0.2255 - val_accuracy: 0.9415\n",
      "Epoch 5/10\n",
      "900/900 [==============================] - 1s 981us/step - loss: 0.1978 - accuracy: 0.9518 - val_loss: 0.2044 - val_accuracy: 0.9454\n",
      "Epoch 6/10\n",
      "900/900 [==============================] - 1s 931us/step - loss: 0.1620 - accuracy: 0.9592 - val_loss: 0.1849 - val_accuracy: 0.9507\n",
      "Epoch 7/10\n",
      "900/900 [==============================] - 1s 949us/step - loss: 0.1344 - accuracy: 0.9655 - val_loss: 0.1753 - val_accuracy: 0.9526\n",
      "Epoch 8/10\n",
      "900/900 [==============================] - 1s 959us/step - loss: 0.1157 - accuracy: 0.9703 - val_loss: 0.1683 - val_accuracy: 0.9553\n",
      "Epoch 9/10\n",
      "900/900 [==============================] - 1s 940us/step - loss: 0.1024 - accuracy: 0.9729 - val_loss: 0.1803 - val_accuracy: 0.9509\n",
      "Epoch 10/10\n",
      "900/900 [==============================] - 1s 954us/step - loss: 0.0926 - accuracy: 0.9758 - val_loss: 0.1592 - val_accuracy: 0.9563\n",
      "Epoch 1/10\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.6718 - accuracy: 0.8257 - val_loss: 0.2004 - val_accuracy: 0.9417\n",
      "Epoch 2/10\n",
      "900/900 [==============================] - 1s 968us/step - loss: 0.1712 - accuracy: 0.9513 - val_loss: 0.1450 - val_accuracy: 0.9583\n",
      "Epoch 3/10\n",
      "900/900 [==============================] - 1s 953us/step - loss: 0.1139 - accuracy: 0.9672 - val_loss: 0.1285 - val_accuracy: 0.9639\n",
      "Epoch 4/10\n",
      "900/900 [==============================] - 1s 951us/step - loss: 0.0864 - accuracy: 0.9744 - val_loss: 0.1225 - val_accuracy: 0.9653\n",
      "Epoch 5/10\n",
      "900/900 [==============================] - 1s 945us/step - loss: 0.0706 - accuracy: 0.9792 - val_loss: 0.1158 - val_accuracy: 0.9673\n",
      "Epoch 6/10\n",
      "900/900 [==============================] - 1s 947us/step - loss: 0.0566 - accuracy: 0.9828 - val_loss: 0.1172 - val_accuracy: 0.9674\n",
      "Epoch 7/10\n",
      "900/900 [==============================] - 1s 961us/step - loss: 0.0460 - accuracy: 0.9858 - val_loss: 0.1163 - val_accuracy: 0.9666\n",
      "Epoch 8/10\n",
      "900/900 [==============================] - 1s 955us/step - loss: 0.0400 - accuracy: 0.9883 - val_loss: 0.1186 - val_accuracy: 0.9682\n",
      "Epoch 9/10\n",
      "900/900 [==============================] - 1s 945us/step - loss: 0.0383 - accuracy: 0.9883 - val_loss: 0.1364 - val_accuracy: 0.9641\n",
      "Epoch 10/10\n",
      "900/900 [==============================] - 1s 942us/step - loss: 0.0289 - accuracy: 0.9905 - val_loss: 0.1235 - val_accuracy: 0.9679\n",
      "Epoch 1/10\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.7399 - accuracy: 0.7675 - val_loss: 0.2300 - val_accuracy: 0.9318\n",
      "Epoch 2/10\n",
      "900/900 [==============================] - 1s 949us/step - loss: 0.1811 - accuracy: 0.9469 - val_loss: 0.1577 - val_accuracy: 0.9534\n",
      "Epoch 3/10\n",
      "900/900 [==============================] - 1s 962us/step - loss: 0.1202 - accuracy: 0.9624 - val_loss: 0.1389 - val_accuracy: 0.9583\n",
      "Epoch 4/10\n",
      "900/900 [==============================] - 1s 947us/step - loss: 0.0991 - accuracy: 0.9705 - val_loss: 0.1259 - val_accuracy: 0.9629\n",
      "Epoch 5/10\n",
      "900/900 [==============================] - 1s 952us/step - loss: 0.0816 - accuracy: 0.9742 - val_loss: 0.1298 - val_accuracy: 0.9627\n",
      "Epoch 6/10\n",
      "900/900 [==============================] - 1s 955us/step - loss: 0.0677 - accuracy: 0.9789 - val_loss: 0.1266 - val_accuracy: 0.9650\n",
      "Epoch 7/10\n",
      "900/900 [==============================] - 1s 946us/step - loss: 0.0567 - accuracy: 0.9828 - val_loss: 0.1200 - val_accuracy: 0.9653\n",
      "Epoch 8/10\n",
      "900/900 [==============================] - 1s 960us/step - loss: 0.0490 - accuracy: 0.9850 - val_loss: 0.1253 - val_accuracy: 0.9642\n",
      "Epoch 9/10\n",
      "900/900 [==============================] - 1s 956us/step - loss: 0.0442 - accuracy: 0.9865 - val_loss: 0.1199 - val_accuracy: 0.9692\n",
      "Epoch 10/10\n",
      "900/900 [==============================] - 1s 959us/step - loss: 0.0341 - accuracy: 0.9892 - val_loss: 0.1365 - val_accuracy: 0.9646\n"
     ]
    }
   ],
   "source": [
    " for func in ['sigmoid','tanh','relu']:\n",
    "    # 랜덤시드값\n",
    "    tf.random.set_seed(14)\n",
    "\n",
    "    # 모델 구현\n",
    "    model = Sequential() # 객체 생성\n",
    "\n",
    "    # 데이터 입력받는 레이어\n",
    "    # Dense(출력데이터차원, 활성화함수, 입력데이터차원)\n",
    "    model.add(Dense(64, activation=func, input_shape=(28*28,)))\n",
    "\n",
    "    # 레이어 추가\n",
    "    model.add(Dense(32, activation=func))\n",
    "    model.add(Dense(32, activation=func))\n",
    "    model.add(Dense(32, activation=func))\n",
    "\n",
    "    # 출력레이어\n",
    "    # label 값의 종류만큼 차원 지정\n",
    "    # 활성화함수 -> softmax\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    # 모델 설정\n",
    "    # compile()\n",
    "    # 최적화기법 : adam(learning_rate=0.001)\n",
    "    # 손실함수 : categorical_crossentropy\n",
    "    # 평가지표 : accuracy\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # 학습\n",
    "    # epochs : 학습횟수\n",
    "    # validation_data : 검증데이터\n",
    "    model.fit(train_x, train_y, epochs=10, batch_size=50, validation_data=(valid_x, valid_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### softmax 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float32, numpy=array([0.27800977, 0.30724832, 0.41474187], dtype=float32)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# softmax 함수\n",
    "tf.nn.softmax([0.1,0.2,0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.27800977, 0.30724832, 0.41474187], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.nn.softmax([0.1,0.2,0.5]).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.nn.softmax([0.1,0.2,0.5]).numpy().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 설정(compile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "900/900 [==============================] - 2s 1ms/step - loss: 0.7399 - accuracy: 0.7675 - val_loss: 0.2300 - val_accuracy: 0.9318\n",
      "Epoch 2/10\n",
      "900/900 [==============================] - 1s 972us/step - loss: 0.1811 - accuracy: 0.9469 - val_loss: 0.1577 - val_accuracy: 0.9534\n",
      "Epoch 3/10\n",
      "900/900 [==============================] - 1s 967us/step - loss: 0.1202 - accuracy: 0.9624 - val_loss: 0.1389 - val_accuracy: 0.9583\n",
      "Epoch 4/10\n",
      "900/900 [==============================] - 1s 992us/step - loss: 0.0991 - accuracy: 0.9705 - val_loss: 0.1259 - val_accuracy: 0.9629\n",
      "Epoch 5/10\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.0816 - accuracy: 0.9742 - val_loss: 0.1298 - val_accuracy: 0.9627\n",
      "Epoch 6/10\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.0677 - accuracy: 0.9789 - val_loss: 0.1266 - val_accuracy: 0.9650\n",
      "Epoch 7/10\n",
      "900/900 [==============================] - 1s 971us/step - loss: 0.0567 - accuracy: 0.9828 - val_loss: 0.1200 - val_accuracy: 0.9653\n",
      "Epoch 8/10\n",
      "900/900 [==============================] - 1s 993us/step - loss: 0.0490 - accuracy: 0.9850 - val_loss: 0.1253 - val_accuracy: 0.9642\n",
      "Epoch 9/10\n",
      "900/900 [==============================] - 1s 980us/step - loss: 0.0442 - accuracy: 0.9865 - val_loss: 0.1199 - val_accuracy: 0.9692\n",
      "Epoch 10/10\n",
      "900/900 [==============================] - 1s 978us/step - loss: 0.0341 - accuracy: 0.9892 - val_loss: 0.1365 - val_accuracy: 0.9646\n",
      "Epoch 1/10\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 1.7578 - accuracy: 0.4100 - val_loss: 0.4771 - val_accuracy: 0.8643\n",
      "Epoch 2/10\n",
      "900/900 [==============================] - 1s 940us/step - loss: 0.4339 - accuracy: 0.8750 - val_loss: 0.3524 - val_accuracy: 0.8994\n",
      "Epoch 3/10\n",
      "900/900 [==============================] - 1s 906us/step - loss: 0.3287 - accuracy: 0.9046 - val_loss: 0.2968 - val_accuracy: 0.9133\n",
      "Epoch 4/10\n",
      "900/900 [==============================] - 1s 895us/step - loss: 0.2839 - accuracy: 0.9200 - val_loss: 0.2606 - val_accuracy: 0.9241\n",
      "Epoch 5/10\n",
      "900/900 [==============================] - 1s 912us/step - loss: 0.2495 - accuracy: 0.9278 - val_loss: 0.2448 - val_accuracy: 0.9282\n",
      "Epoch 6/10\n",
      "900/900 [==============================] - 1s 907us/step - loss: 0.2213 - accuracy: 0.9355 - val_loss: 0.2086 - val_accuracy: 0.9405\n",
      "Epoch 7/10\n",
      "900/900 [==============================] - 1s 902us/step - loss: 0.1874 - accuracy: 0.9457 - val_loss: 0.1926 - val_accuracy: 0.9448\n",
      "Epoch 8/10\n",
      "900/900 [==============================] - 1s 895us/step - loss: 0.1712 - accuracy: 0.9490 - val_loss: 0.1826 - val_accuracy: 0.9479\n",
      "Epoch 9/10\n",
      "900/900 [==============================] - 1s 897us/step - loss: 0.1585 - accuracy: 0.9527 - val_loss: 0.1787 - val_accuracy: 0.9469\n",
      "Epoch 10/10\n",
      "900/900 [==============================] - 1s 897us/step - loss: 0.1475 - accuracy: 0.9568 - val_loss: 0.1671 - val_accuracy: 0.9495\n",
      "Epoch 1/10\n",
      "900/900 [==============================] - 2s 1ms/step - loss: 0.6870 - accuracy: 0.7884 - val_loss: 0.2160 - val_accuracy: 0.9346\n",
      "Epoch 2/10\n",
      "900/900 [==============================] - 1s 978us/step - loss: 0.1886 - accuracy: 0.9437 - val_loss: 0.1594 - val_accuracy: 0.9531\n",
      "Epoch 3/10\n",
      "900/900 [==============================] - 1s 994us/step - loss: 0.1285 - accuracy: 0.9620 - val_loss: 0.1429 - val_accuracy: 0.9591\n",
      "Epoch 4/10\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.1053 - accuracy: 0.9694 - val_loss: 0.1355 - val_accuracy: 0.9630\n",
      "Epoch 5/10\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.0875 - accuracy: 0.9734 - val_loss: 0.1281 - val_accuracy: 0.9652\n",
      "Epoch 6/10\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.0733 - accuracy: 0.9779 - val_loss: 0.1309 - val_accuracy: 0.9668\n",
      "Epoch 7/10\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.0608 - accuracy: 0.9822 - val_loss: 0.1341 - val_accuracy: 0.9670\n",
      "Epoch 8/10\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.0584 - accuracy: 0.9834 - val_loss: 0.1341 - val_accuracy: 0.9663\n",
      "Epoch 9/10\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.0501 - accuracy: 0.9849 - val_loss: 0.1391 - val_accuracy: 0.9655\n",
      "Epoch 10/10\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.0444 - accuracy: 0.9870 - val_loss: 0.1409 - val_accuracy: 0.9685\n"
     ]
    }
   ],
   "source": [
    "# import (optimizer 클래스)\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "\n",
    "for opt in [Adam(), SGD(), RMSprop()]:\n",
    "    # 랜덤시드값\n",
    "    tf.random.set_seed(14)\n",
    "\n",
    "    # 모델 구현\n",
    "    model = Sequential() # 객체 생성\n",
    "\n",
    "    # 데이터 입력받는 레이어\n",
    "    # Dense(출력데이터차원, 활성화함수, 입력데이터차원)\n",
    "    model.add(Dense(64, activation='relu', input_shape=(28*28,)))\n",
    "\n",
    "    # 레이어 추가\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "\n",
    "    # 출력레이어\n",
    "    # label 값의 종류만큼 차원 지정\n",
    "    # 활성화함수 -> softmax\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    # 모델 설정\n",
    "    # compile()\n",
    "    # 최적화기법 : adam(learning_rate=0.001)\n",
    "    # 손실함수 : categorical_crossentropy\n",
    "    # 평가지표 : accuracy\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # 학습\n",
    "    # epochs : 학습횟수\n",
    "    # validation_data : 검증데이터\n",
    "    model.fit(train_x, train_y, epochs=10, batch_size=50, validation_data=(valid_x, valid_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 성능평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "900/900 [==============================] - 2s 1ms/step - loss: 0.7399 - accuracy: 0.7675 - val_loss: 0.2300 - val_accuracy: 0.9318\n",
      "Epoch 2/50\n",
      "900/900 [==============================] - 1s 973us/step - loss: 0.1811 - accuracy: 0.9469 - val_loss: 0.1577 - val_accuracy: 0.9534\n",
      "Epoch 3/50\n",
      "900/900 [==============================] - 1s 975us/step - loss: 0.1202 - accuracy: 0.9624 - val_loss: 0.1389 - val_accuracy: 0.9583\n",
      "Epoch 4/50\n",
      "900/900 [==============================] - 1s 989us/step - loss: 0.0991 - accuracy: 0.9705 - val_loss: 0.1259 - val_accuracy: 0.9629\n",
      "Epoch 5/50\n",
      "900/900 [==============================] - 1s 976us/step - loss: 0.0816 - accuracy: 0.9742 - val_loss: 0.1298 - val_accuracy: 0.9627\n",
      "Epoch 6/50\n",
      "900/900 [==============================] - 1s 964us/step - loss: 0.0677 - accuracy: 0.9789 - val_loss: 0.1266 - val_accuracy: 0.9650\n",
      "Epoch 7/50\n",
      "900/900 [==============================] - 1s 971us/step - loss: 0.0567 - accuracy: 0.9828 - val_loss: 0.1200 - val_accuracy: 0.9653\n",
      "Epoch 8/50\n",
      "900/900 [==============================] - 1s 984us/step - loss: 0.0490 - accuracy: 0.9850 - val_loss: 0.1253 - val_accuracy: 0.9642\n",
      "Epoch 9/50\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.0442 - accuracy: 0.9865 - val_loss: 0.1199 - val_accuracy: 0.9692\n",
      "Epoch 10/50\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.0341 - accuracy: 0.9892 - val_loss: 0.1365 - val_accuracy: 0.9646\n",
      "Epoch 11/50\n",
      "900/900 [==============================] - 1s 977us/step - loss: 0.0314 - accuracy: 0.9905 - val_loss: 0.1249 - val_accuracy: 0.9685\n",
      "Epoch 12/50\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.0292 - accuracy: 0.9911 - val_loss: 0.1569 - val_accuracy: 0.9618\n",
      "Epoch 13/50\n",
      "900/900 [==============================] - 1s 981us/step - loss: 0.0284 - accuracy: 0.9910 - val_loss: 0.1565 - val_accuracy: 0.9623\n",
      "Epoch 14/50\n",
      "900/900 [==============================] - 1s 993us/step - loss: 0.0282 - accuracy: 0.9905 - val_loss: 0.1355 - val_accuracy: 0.9702\n",
      "Epoch 15/50\n",
      "900/900 [==============================] - 1s 1000us/step - loss: 0.0214 - accuracy: 0.9928 - val_loss: 0.1622 - val_accuracy: 0.9639\n",
      "Epoch 16/50\n",
      "900/900 [==============================] - 1s 982us/step - loss: 0.0238 - accuracy: 0.9922 - val_loss: 0.1525 - val_accuracy: 0.9679\n",
      "Epoch 17/50\n",
      "900/900 [==============================] - 1s 973us/step - loss: 0.0277 - accuracy: 0.9911 - val_loss: 0.1558 - val_accuracy: 0.9669\n",
      "Epoch 18/50\n",
      "900/900 [==============================] - 1s 975us/step - loss: 0.0169 - accuracy: 0.9947 - val_loss: 0.1524 - val_accuracy: 0.9679\n",
      "Epoch 19/50\n",
      "900/900 [==============================] - 1s 975us/step - loss: 0.0184 - accuracy: 0.9941 - val_loss: 0.1794 - val_accuracy: 0.9635\n",
      "Epoch 20/50\n",
      "900/900 [==============================] - 1s 987us/step - loss: 0.0150 - accuracy: 0.9949 - val_loss: 0.1500 - val_accuracy: 0.9687\n",
      "Epoch 21/50\n",
      "900/900 [==============================] - 1s 971us/step - loss: 0.0152 - accuracy: 0.9948 - val_loss: 0.1742 - val_accuracy: 0.9651\n",
      "Epoch 22/50\n",
      "900/900 [==============================] - 1s 985us/step - loss: 0.0203 - accuracy: 0.9939 - val_loss: 0.1733 - val_accuracy: 0.9685\n",
      "Epoch 23/50\n",
      "900/900 [==============================] - 1s 984us/step - loss: 0.0129 - accuracy: 0.9960 - val_loss: 0.1540 - val_accuracy: 0.9696\n",
      "Epoch 24/50\n",
      "900/900 [==============================] - 1s 971us/step - loss: 0.0144 - accuracy: 0.9955 - val_loss: 0.1543 - val_accuracy: 0.9719\n",
      "Epoch 25/50\n",
      "900/900 [==============================] - 1s 973us/step - loss: 0.0121 - accuracy: 0.9961 - val_loss: 0.1489 - val_accuracy: 0.9726\n",
      "Epoch 26/50\n",
      "900/900 [==============================] - 1s 987us/step - loss: 0.0116 - accuracy: 0.9959 - val_loss: 0.1640 - val_accuracy: 0.9695\n",
      "Epoch 27/50\n",
      "900/900 [==============================] - 1s 973us/step - loss: 0.0134 - accuracy: 0.9959 - val_loss: 0.1697 - val_accuracy: 0.9691\n",
      "Epoch 28/50\n",
      "900/900 [==============================] - 1s 980us/step - loss: 0.0138 - accuracy: 0.9953 - val_loss: 0.1856 - val_accuracy: 0.9677\n",
      "Epoch 29/50\n",
      "900/900 [==============================] - 1s 987us/step - loss: 0.0143 - accuracy: 0.9950 - val_loss: 0.1730 - val_accuracy: 0.9701\n",
      "Epoch 30/50\n",
      "900/900 [==============================] - 1s 978us/step - loss: 0.0104 - accuracy: 0.9968 - val_loss: 0.1975 - val_accuracy: 0.9677\n",
      "Epoch 31/50\n",
      "900/900 [==============================] - 1s 970us/step - loss: 0.0210 - accuracy: 0.9938 - val_loss: 0.1769 - val_accuracy: 0.9711\n",
      "Epoch 32/50\n",
      "900/900 [==============================] - 1s 974us/step - loss: 0.0107 - accuracy: 0.9964 - val_loss: 0.1890 - val_accuracy: 0.9690\n",
      "Epoch 33/50\n",
      "900/900 [==============================] - 1s 985us/step - loss: 0.0119 - accuracy: 0.9958 - val_loss: 0.1911 - val_accuracy: 0.9697\n",
      "Epoch 34/50\n",
      "900/900 [==============================] - 1s 974us/step - loss: 0.0083 - accuracy: 0.9973 - val_loss: 0.1991 - val_accuracy: 0.9692\n",
      "Epoch 35/50\n",
      "900/900 [==============================] - 1s 976us/step - loss: 0.0117 - accuracy: 0.9963 - val_loss: 0.2218 - val_accuracy: 0.9651\n",
      "Epoch 36/50\n",
      "900/900 [==============================] - 1s 975us/step - loss: 0.0120 - accuracy: 0.9961 - val_loss: 0.1877 - val_accuracy: 0.9711\n",
      "Epoch 37/50\n",
      "900/900 [==============================] - 1s 972us/step - loss: 0.0079 - accuracy: 0.9975 - val_loss: 0.1845 - val_accuracy: 0.9707\n",
      "Epoch 38/50\n",
      "900/900 [==============================] - 1s 965us/step - loss: 0.0121 - accuracy: 0.9962 - val_loss: 0.1954 - val_accuracy: 0.9681\n",
      "Epoch 39/50\n",
      "900/900 [==============================] - 1s 976us/step - loss: 0.0113 - accuracy: 0.9966 - val_loss: 0.1892 - val_accuracy: 0.9710\n",
      "Epoch 40/50\n",
      "900/900 [==============================] - 1s 983us/step - loss: 0.0107 - accuracy: 0.9964 - val_loss: 0.1976 - val_accuracy: 0.9703\n",
      "Epoch 41/50\n",
      "900/900 [==============================] - 1s 973us/step - loss: 0.0102 - accuracy: 0.9969 - val_loss: 0.2180 - val_accuracy: 0.9660\n",
      "Epoch 42/50\n",
      "900/900 [==============================] - 1s 967us/step - loss: 0.0108 - accuracy: 0.9965 - val_loss: 0.2216 - val_accuracy: 0.9686\n",
      "Epoch 43/50\n",
      "900/900 [==============================] - 1s 968us/step - loss: 0.0086 - accuracy: 0.9973 - val_loss: 0.2379 - val_accuracy: 0.9674\n",
      "Epoch 44/50\n",
      "900/900 [==============================] - 1s 987us/step - loss: 0.0096 - accuracy: 0.9971 - val_loss: 0.2208 - val_accuracy: 0.9684\n",
      "Epoch 45/50\n",
      "900/900 [==============================] - 1s 973us/step - loss: 0.0106 - accuracy: 0.9967 - val_loss: 0.1801 - val_accuracy: 0.9723\n",
      "Epoch 46/50\n",
      "900/900 [==============================] - 1s 964us/step - loss: 0.0048 - accuracy: 0.9984 - val_loss: 0.1950 - val_accuracy: 0.9719\n",
      "Epoch 47/50\n",
      "900/900 [==============================] - 1s 982us/step - loss: 0.0094 - accuracy: 0.9971 - val_loss: 0.2327 - val_accuracy: 0.9673\n",
      "Epoch 48/50\n",
      "900/900 [==============================] - 1s 965us/step - loss: 0.0123 - accuracy: 0.9961 - val_loss: 0.2237 - val_accuracy: 0.9693\n",
      "Epoch 49/50\n",
      "900/900 [==============================] - 1s 990us/step - loss: 0.0095 - accuracy: 0.9970 - val_loss: 0.2132 - val_accuracy: 0.9701\n",
      "Epoch 50/50\n",
      "900/900 [==============================] - 1s 971us/step - loss: 0.0071 - accuracy: 0.9978 - val_loss: 0.1969 - val_accuracy: 0.9701\n"
     ]
    }
   ],
   "source": [
    "# 랜덤시드값\n",
    "tf.random.set_seed(14)\n",
    "\n",
    "# 모델 구현\n",
    "model = Sequential() # 객체 생성\n",
    "\n",
    "# 데이터 입력받는 레이어\n",
    "# Dense(출력데이터차원, 활성화함수, 입력데이터차원)\n",
    "model.add(Dense(64, activation='relu', input_shape=(28*28,)))\n",
    "\n",
    "# 레이어 추가\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "\n",
    "# 출력레이어\n",
    "# label 값의 종류만큼 차원 지정\n",
    "# 활성화함수 -> softmax\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# 모델 설정\n",
    "# compile()\n",
    "# 최적화기법 : adam(learning_rate=0.001)\n",
    "# 손실함수 : categorical_crossentropy\n",
    "# 평가지표 : accuracy\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 학습\n",
    "# epochs : 학습횟수\n",
    "# validation_data : 검증데이터\n",
    "history = model.fit(train_x, train_y, epochs=50, batch_size=50, validation_data=(valid_x, valid_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.415483295917511,\n",
       "  0.1723768413066864,\n",
       "  0.12320245057344437,\n",
       "  0.09952303767204285,\n",
       "  0.08156460523605347,\n",
       "  0.07012326270341873,\n",
       "  0.061651721596717834,\n",
       "  0.05189445987343788,\n",
       "  0.04700708016753197,\n",
       "  0.03993473947048187,\n",
       "  0.03554048761725426,\n",
       "  0.034410301595926285,\n",
       "  0.03152928873896599,\n",
       "  0.030571766197681427,\n",
       "  0.02277863770723343,\n",
       "  0.02759694866836071,\n",
       "  0.026451369747519493,\n",
       "  0.019688406959176064,\n",
       "  0.021337926387786865,\n",
       "  0.019747022539377213,\n",
       "  0.019017476588487625,\n",
       "  0.01821376383304596,\n",
       "  0.01654270850121975,\n",
       "  0.01808464713394642,\n",
       "  0.016494043171405792,\n",
       "  0.013868553563952446,\n",
       "  0.013958444818854332,\n",
       "  0.015056252479553223,\n",
       "  0.014768964610993862,\n",
       "  0.010741262696683407,\n",
       "  0.015690967440605164,\n",
       "  0.013416273519396782,\n",
       "  0.012580003589391708,\n",
       "  0.012742801569402218,\n",
       "  0.012377594597637653,\n",
       "  0.011677091009914875,\n",
       "  0.008536017499864101,\n",
       "  0.013800066895782948,\n",
       "  0.009743292815983295,\n",
       "  0.011349782347679138,\n",
       "  0.011184933595359325,\n",
       "  0.010506885126233101,\n",
       "  0.010038422420620918,\n",
       "  0.009654438123106956,\n",
       "  0.011235841549932957,\n",
       "  0.008283555507659912,\n",
       "  0.00823951791971922,\n",
       "  0.009709215722978115,\n",
       "  0.009666942059993744,\n",
       "  0.009475682862102985],\n",
       " 'accuracy': [0.8757555484771729,\n",
       "  0.9487777948379517,\n",
       "  0.9624888896942139,\n",
       "  0.9699777960777283,\n",
       "  0.9742000102996826,\n",
       "  0.9783333539962769,\n",
       "  0.9806444644927979,\n",
       "  0.9831110835075378,\n",
       "  0.9851111173629761,\n",
       "  0.9872221946716309,\n",
       "  0.98862224817276,\n",
       "  0.9888222217559814,\n",
       "  0.9900222420692444,\n",
       "  0.9900888800621033,\n",
       "  0.9925110936164856,\n",
       "  0.9907777905464172,\n",
       "  0.9910666942596436,\n",
       "  0.9938889145851135,\n",
       "  0.9929555654525757,\n",
       "  0.9936222434043884,\n",
       "  0.9936666488647461,\n",
       "  0.9942222237586975,\n",
       "  0.9949555397033691,\n",
       "  0.9941555261611938,\n",
       "  0.9947333335876465,\n",
       "  0.9951778054237366,\n",
       "  0.9954666495323181,\n",
       "  0.9949111342430115,\n",
       "  0.995044469833374,\n",
       "  0.9965999722480774,\n",
       "  0.9950666427612305,\n",
       "  0.9951333403587341,\n",
       "  0.9958222508430481,\n",
       "  0.9960444569587708,\n",
       "  0.9959999918937683,\n",
       "  0.9961110949516296,\n",
       "  0.9973333477973938,\n",
       "  0.9956666827201843,\n",
       "  0.9970444440841675,\n",
       "  0.9962888956069946,\n",
       "  0.9963777661323547,\n",
       "  0.9964666962623596,\n",
       "  0.9968888759613037,\n",
       "  0.9971333146095276,\n",
       "  0.9966222047805786,\n",
       "  0.9973111152648926,\n",
       "  0.9973999857902527,\n",
       "  0.9968666434288025,\n",
       "  0.9969555735588074,\n",
       "  0.9969555735588074],\n",
       " 'val_loss': [0.2300296127796173,\n",
       "  0.15769322216510773,\n",
       "  0.1389206200838089,\n",
       "  0.1258501559495926,\n",
       "  0.12975116074085236,\n",
       "  0.12655703723430634,\n",
       "  0.12002398073673248,\n",
       "  0.12532757222652435,\n",
       "  0.11994244903326035,\n",
       "  0.13652560114860535,\n",
       "  0.12494543194770813,\n",
       "  0.1569388061761856,\n",
       "  0.15654920041561127,\n",
       "  0.13546927273273468,\n",
       "  0.1621713638305664,\n",
       "  0.15252825617790222,\n",
       "  0.1558152437210083,\n",
       "  0.15236836671829224,\n",
       "  0.17943522334098816,\n",
       "  0.14996188879013062,\n",
       "  0.17415139079093933,\n",
       "  0.17332850396633148,\n",
       "  0.1540130078792572,\n",
       "  0.15428651869297028,\n",
       "  0.14894117414951324,\n",
       "  0.1640438586473465,\n",
       "  0.16972674429416656,\n",
       "  0.18564510345458984,\n",
       "  0.1730288565158844,\n",
       "  0.19754929840564728,\n",
       "  0.17693190276622772,\n",
       "  0.18901321291923523,\n",
       "  0.1911233812570572,\n",
       "  0.19906389713287354,\n",
       "  0.22177664935588837,\n",
       "  0.18766358494758606,\n",
       "  0.18447202444076538,\n",
       "  0.19540949165821075,\n",
       "  0.18921127915382385,\n",
       "  0.19760841131210327,\n",
       "  0.21800507605075836,\n",
       "  0.221560537815094,\n",
       "  0.2379165142774582,\n",
       "  0.2208445817232132,\n",
       "  0.1801297813653946,\n",
       "  0.19495521485805511,\n",
       "  0.23273232579231262,\n",
       "  0.22372311353683472,\n",
       "  0.21317289769649506,\n",
       "  0.1969149261713028],\n",
       " 'val_accuracy': [0.9318000078201294,\n",
       "  0.9534000158309937,\n",
       "  0.9583333134651184,\n",
       "  0.962933361530304,\n",
       "  0.9627333283424377,\n",
       "  0.9649999737739563,\n",
       "  0.9652666449546814,\n",
       "  0.9642000198364258,\n",
       "  0.9692000150680542,\n",
       "  0.9646000266075134,\n",
       "  0.9684666395187378,\n",
       "  0.9617999792098999,\n",
       "  0.9623333215713501,\n",
       "  0.9702000021934509,\n",
       "  0.963866651058197,\n",
       "  0.9679333567619324,\n",
       "  0.966866672039032,\n",
       "  0.9678666591644287,\n",
       "  0.9634666442871094,\n",
       "  0.968666672706604,\n",
       "  0.96506667137146,\n",
       "  0.9684666395187378,\n",
       "  0.9696000218391418,\n",
       "  0.9718666672706604,\n",
       "  0.972599983215332,\n",
       "  0.9694666862487793,\n",
       "  0.9691333174705505,\n",
       "  0.9676666855812073,\n",
       "  0.9701333045959473,\n",
       "  0.9676666855812073,\n",
       "  0.9710666537284851,\n",
       "  0.968999981880188,\n",
       "  0.9696666598320007,\n",
       "  0.9692000150680542,\n",
       "  0.9651333093643188,\n",
       "  0.9710666537284851,\n",
       "  0.9707333445549011,\n",
       "  0.9681333303451538,\n",
       "  0.9710000157356262,\n",
       "  0.9702666401863098,\n",
       "  0.9660000205039978,\n",
       "  0.9685999751091003,\n",
       "  0.9674000144004822,\n",
       "  0.9684000015258789,\n",
       "  0.972266674041748,\n",
       "  0.9718666672706604,\n",
       "  0.9673333168029785,\n",
       "  0.9692666530609131,\n",
       "  0.9700666666030884,\n",
       "  0.9701333045959473]}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 학습데이터 로스\n",
    "plt.plot(history.history['loss'], c='r')\n",
    "# 검증데이터 로스\n",
    "plt.plot(history.history['val_loss'], c='g')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 783us/step - loss: 0.1687 - accuracy: 0.9725\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.16865012049674988, 0.9725000262260437]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 50회 학습한 모델(정확도 99%)로 테스트데이터 예측\n",
    "model.evaluate(test_x, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 혼동행렬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 962,    1,    3,    1,    1,    1,    2,    4,    4,    1],\n",
       "       [   0, 1125,    2,    2,    0,    0,    1,    1,    4,    0],\n",
       "       [   4,    3, 1001,    4,    1,    0,    2,    9,    8,    0],\n",
       "       [   1,    0,    6,  980,    0,    5,    0,    6,    9,    3],\n",
       "       [   0,    0,    2,    1,  959,    0,    5,    0,    0,   15],\n",
       "       [   4,    0,    0,   12,    2,  857,    5,    1,   11,    0],\n",
       "       [   3,    5,    2,    1,    5,    8,  931,    1,    2,    0],\n",
       "       [   1,    3,    9,    2,    1,    0,    0,  997,   10,    5],\n",
       "       [   7,    0,    1,    4,    2,    2,    2,    4,  949,    3],\n",
       "       [   2,    2,    0,    5,   14,    5,    0,    5,   12,  964]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "pred = model.predict(test_x)\n",
    "# 실제:[1,0,1], 예측:[1,0,0]\n",
    "confusion_matrix(np.argmax(test_y, axis=1), np.argmax(pred, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 분류보고서"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98       980\n",
      "           1       0.99      0.99      0.99      1135\n",
      "           2       0.98      0.97      0.97      1032\n",
      "           3       0.97      0.97      0.97      1010\n",
      "           4       0.97      0.98      0.98       982\n",
      "           5       0.98      0.96      0.97       892\n",
      "           6       0.98      0.97      0.98       958\n",
      "           7       0.97      0.97      0.97      1028\n",
      "           8       0.94      0.97      0.96       974\n",
      "           9       0.97      0.96      0.96      1009\n",
      "\n",
      "    accuracy                           0.97     10000\n",
      "   macro avg       0.97      0.97      0.97     10000\n",
      "weighted avg       0.97      0.97      0.97     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(np.argmax(test_y, axis=1), np.argmax(pred, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.32941176, 0.7254902 , 0.62352941,\n",
       "        0.59215686, 0.23529412, 0.14117647, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.87058824, 0.99607843, 0.99607843, 0.99607843, 0.99607843,\n",
       "        0.94509804, 0.77647059, 0.77647059, 0.77647059, 0.77647059,\n",
       "        0.77647059, 0.77647059, 0.77647059, 0.77647059, 0.66666667,\n",
       "        0.20392157, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.2627451 , 0.44705882,\n",
       "        0.28235294, 0.44705882, 0.63921569, 0.89019608, 0.99607843,\n",
       "        0.88235294, 0.99607843, 0.99607843, 0.99607843, 0.98039216,\n",
       "        0.89803922, 0.99607843, 0.99607843, 0.54901961, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.06666667, 0.25882353, 0.05490196, 0.2627451 ,\n",
       "        0.2627451 , 0.2627451 , 0.23137255, 0.08235294, 0.9254902 ,\n",
       "        0.99607843, 0.41568627, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.3254902 , 0.99215686, 0.81960784, 0.07058824,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.08627451, 0.91372549,\n",
       "        1.        , 0.3254902 , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.50588235, 0.99607843, 0.93333333, 0.17254902,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.23137255, 0.97647059,\n",
       "        0.99607843, 0.24313725, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.52156863, 0.99607843, 0.73333333, 0.01960784,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.03529412, 0.80392157,\n",
       "        0.97254902, 0.22745098, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.49411765, 0.99607843, 0.71372549, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.29411765, 0.98431373,\n",
       "        0.94117647, 0.22352941, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.0745098 , 0.86666667, 0.99607843, 0.65098039, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.01176471, 0.79607843, 0.99607843,\n",
       "        0.85882353, 0.1372549 , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.14901961, 0.99607843, 0.99607843, 0.30196078, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.12156863, 0.87843137, 0.99607843,\n",
       "        0.45098039, 0.00392157, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.52156863, 0.99607843, 0.99607843, 0.20392157, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.23921569, 0.94901961, 0.99607843,\n",
       "        0.99607843, 0.20392157, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.4745098 , 0.99607843, 0.99607843, 0.85882353, 0.15686275,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.4745098 , 0.99607843,\n",
       "        0.81176471, 0.07058824, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.expand_dims(test_x[0],0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.1477916e-16, 8.3407722e-13, 1.3344019e-14, 1.8439465e-11,\n",
       "        1.5597593e-13, 4.1426674e-17, 1.7765995e-19, 1.0000000e+00,\n",
       "        1.4629619e-14, 1.4410050e-12]], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 확률값을 출력\n",
    "model.predict(np.expand_dims(test_x[0],0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anconda\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([7], dtype=int64)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# label값으로 출력\n",
    "model.predict_classes(np.expand_dims(test_x[0],0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.5.1.48-cp38-cp38-win_amd64.whl (34.9 MB)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\anconda\\lib\\site-packages (from opencv-python) (1.19.2)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.5.1.48\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-2e5f4e0a5159>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'2.jpg'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIMREAD_GRAYSCALE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# 이미지 리사이징\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "img = cv2.imread('2.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "# 이미지 리사이징\n",
    "img = cv2.resize(img, None, fx=28/img.shape[1], fy=28/img.shape[0])\n",
    "img = img/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img,'gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = img.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(np.expand_dims(img,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict_classes(np.expand_dims(img,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict_classes(np.expand_dims(test_x[1],0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
